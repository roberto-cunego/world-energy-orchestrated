# ğŸŒ World Energy Orchestrated  
*Data Engineering Project with Apache Airflow, PostgreSQL, and Real Energy Data*

---

## ğŸ“– Overview
This project demonstrates a modern **data engineering pipeline** that integrates:
- **Global energy statistics** from [Our World in Data](https://ourworldindata.org/energy)
- **Hourly power data for Denmark** from [Energi Data Service (Energinet)](https://www.energidataservice.dk/)
- A **PostgreSQL data warehouse**
- An **Apache Airflow** orchestrator (running in Docker)

The goal is to combine **static global datasets** with **live hourly data** to show how orchestration adds value to continuously updated sources.

---

## ğŸ§± Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Apache Airflow (Docker)           â”‚
â”‚  â”œâ”€ DAG #1: OWID Annual ETL                   â”‚
â”‚  â””â”€ DAG #2: Energinet Hourly ETL (daily)      â”‚
â”‚                                               â”‚
â”‚        â†“ orchestrates                         â”‚
â”‚ PostgreSQL (Data Warehouse)                   â”‚
â”‚  â”œâ”€ silver: normalized tables (countries, etc)â”‚
â”‚  â”œâ”€ gold: materialized views / KPIs           â”‚
â”‚                                               â”‚
â”‚        â†“ visualization                        â”‚
â”‚ pgAdmin / Notebooks / PowerBI                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Tech Stack
- **Docker** â€“ containerization
- **Apache Airflow 3.1** â€“ orchestration
- **PostgreSQL 16** â€“ data warehouse
- **pgAdmin 8** â€“ database management UI
- **Python** (pandas, requests, pyarrow) â€“ data ingestion & transformation

---

## ğŸš€ Setup

### 1ï¸âƒ£ Requirements
- Docker Desktop installed and running  
- macOS / Linux / Windows (tested on macOS)

### 2ï¸âƒ£ Run Airflow + PostgreSQL + pgAdmin
```bash
docker compose build --no-cache
docker compose up airflow-init
docker compose up -d
```

Access:
- Airflow UI â†’ [http://localhost:8080](http://localhost:8080)  (user: `airflow`, pass: `airflow`)
- pgAdmin UI â†’ [http://localhost:8081](http://localhost:8081)  (user: `admin@example.com`, pass: `admin`)

### 3ï¸âƒ£ Folder structure
```
world-energy-orchestrated/
â”œâ”€ dags/             # Airflow DAGs
â”œâ”€ data/             # datasets (OWID, Energinet)
â”œâ”€ logs/             # Airflow logs
â”œâ”€ plugins/          # custom plugins (optional)
â”œâ”€ config/           # config files
â”œâ”€ pgdata/           # PostgreSQL data (volume)
â”œâ”€ docker-compose.yaml
â”œâ”€ Dockerfile
â”œâ”€ requirements.txt
â”œâ”€ .env
â””â”€ README.md
```

---

## ğŸ§© Project Phases

### Phase 1 â€“ Global Energy DW (Our World in Data)
- Download global energy CSVs  
- Load into PostgreSQL (`silver.energy_fact_annual`)  
- Create materialized views:
  - `mv_transition_speed`
  - `mv_efficiency`
  - `mv_country_dashboard`

### Phase 2 â€“ Denmark Hourly Orchestration (Energinet)
- Daily job fetching hourly power data (API)  
- Quality validation & upsert into `fact_power_hourly_dk`  
- Aggregation to monthly KPIs (`gold.mv_dk_energy_mix`)

---

## ğŸ§  Key Learnings
- Designing a **star-schema** for energy data  
- Using **Airflow** for orchestrating periodic updates  
- Building **materialized views** for KPIs  
- Combining **open datasets** with real-time feeds  
- Deploying **end-to-end** pipelines reproducibly in Docker

---

## ğŸ§‘â€ğŸ’» Author
**Roberto Cunego**  
Energy & Data Engineer â€” combining energy analysis with data-driven automation.  
[LinkedIn](https://www.linkedin.com/in/roberto-cunego/) â€¢ [GitHub](https://github.com/roberto-cunego)

---

## ğŸ“„ License
MIT License. Datasets Â© their respective providers.
